
// expressionBase
//     : parenthesizedExpression
//     | parenthesizedExpression callSuffix
//     | constExpr
//     | constExpr callSuffix
//     | string
//     | string callSuffix
//     | listExpr
//     | mapExpr
//     | setExpr
//     | lambdaExpr
//     | THIS
//     | THIS callSuffix
//     | modulePath? anyName
//     | modulePath? anyName functionCallEnd
//     | modulePath? anyName callSuffix
//     | modulePath? anyName typeParamArg? newInstance
//     | modulePath? anyName typeParamArg? newInstance callSuffix
//     | modulePath? anyName typeParamArg? STRING_START stringContents* STRING_END
//     | modulePath? anyName typeParamArg? PLAIN_STRING
//     | sizeOfExpr
//     | jsonExpr
//     | BREAK
//     | CONTINUE
//     ;

// callSuffix
//     : typeParamArg? functionCallParams functionCallEnd?
//     : typeParamArg? functionCallEnd
//     ;

// newInstance
//     : STRUCT_START NL* (newInstanceEntry (commaOrNl newInstanceEntry)* COMMA?)? NL* RBRACKET ;

// newInstanceEntry
//     : modulePath? anyName COLON NL* expression
//     | modulePath? anyName
//     ;

// functionCallParams
//     : LPAREN NL* functionCallParamList? RPAREN ;

// functionCallParamList
//     : expression (commaOrNl expression)* COMMA? NL* ;

// functionCallEnd
//     : lambdaExpr ;

fun Parser.read_expression_base(code: NCode): Parsed<NInstId> {
    let span = lexer.current_token_span

    let inst = when lexer.current_token_kind {
        // parenthesizedExpression
        // parenthesizedExpression callSuffix
        TokenKind::LPAREN -> read_expression_in_parens(code)
        // constExpr
        // constExpr callSuffix
        TokenKind::INT_NUMBER -> read_expression_const_expr(code)
        TokenKind::LONG_NUMBER -> read_expression_const_expr(code)
        TokenKind::FLOAT_NUMBER -> read_expression_const_expr(code)
        TokenKind::PLAIN_STRING -> read_expression_const_expr(code)
        TokenKind::ASCII_STRING -> read_expression_const_expr(code)
        TokenKind::TRUE -> read_expression_const_expr(code)
        TokenKind::FALSE -> read_expression_const_expr(code)
        TokenKind::NULL -> read_expression_const_expr(code)
        TokenKind::NOTHING -> read_expression_const_expr(code)
        // string
        // string callSuffix
        TokenKind::PLAIN_STRING -> read_expression_string_or_call(code)
        TokenKind::STRING_START -> read_expression_string_or_call(code)
        TokenKind::STRING2_START -> read_expression_string_or_call(code)
        // THIS
        // THIS callSuffix
        TokenKind::THIS -> read_expression_this(code)
        // modulePath? anyName
        // modulePath? anyName callSuffix
        // modulePath? anyName typeParamArg? newInstance
        // modulePath? anyName typeParamArg? newInstance callSuffix
        // modulePath? anyName typeParamArg? STRING_START stringContents* STRING_END
        // modulePath? anyName typeParamArg? PLAIN_STRING
        TokenKind::IDENTIFIER -> read_expression_with_name(code)
        // listExpr
        TokenKind::LBRACKET -> read_expression_list(code)
        // mapExpr
        TokenKind::MAP_START -> read_expression_map(code)
        // setExpr
        TokenKind::SET_START -> read_expression_set(code)
        // lambdaExpr
        TokenKind::LAMBDA_START -> read_expression_lambda(code)
        // sizeOfExpr
        TokenKind::SIZE_OF -> read_expression_size_of(code)
        // jsonExpr
        TokenKind::JSON -> read_expression_json(code)
        // BREAK
        TokenKind::BREAK -> read_expression_break(code)
        // CONTINUE
        TokenKind::CONTINUE -> read_expression_continue(code)

        else -> {
            ret parse_error(ParseError::ExpectedExpression, lexer.current_token)
        }
    }

    ret inst
}

fun Parser.read_expression_in_parens(code: NCode): Parsed<NInstId> {
    skip_token_kind(TokenKind::LPAREN)?
    let expr = read_expression(code)?
    skip_token_kind(TokenKind::RPAREN)?
    ret read_expression_call_suffix(code, expr)
}

fun Parser.read_expression_const_expr(code: NCode): Parsed<NInstId> {
    let expr = read_expression_literal(code)?
    ret read_expression_call_suffix(code, expr)
}

fun Parser.read_expression_string_or_call(code: NCode): Parsed<NInstId> {
    let expr = read_expression_string(code)?
    ret read_expression_call_suffix(code, expr)
}

fun Parser.read_expression_this(code: NCode): Parsed<NInstId> {
    let span = lexer.current_token_span
    skip_token_kind(TokenKind::THIS)?

    let inst = code.add_load_var(span, "", "this", None())
    ret read_expression_call_suffix(code, inst.id)
}

fun Parser.read_expression_call_suffix(code: NCode, expr: NInstId): Parsed<NInstId> {
    let span = lexer.current_token_span
    let type_args = []

    if lexer.current_token_kind == TokenKind::LTH {
        type_args = read_type_param_args()?
    }

    // typeParamArg? functionCallParams functionCallEnd?
    if lexer.current_token_kind == TokenKind::LPAREN {
        let span = lexer.current_token_span
        let args = read_expression_function_call_params(code)?
        args.add_first(expr)

        if lexer.current_token_kind == TokenKind::LAMBDA_START {
            args[] = read_expression_function_call_end(code)?
        }

        let inst = code.add_fun_call(span, "", "call", args, type_args)
        ret found(inst.id)
    }

    // typeParamArg? functionCallEnd
    if lexer.current_token_kind == TokenKind::LAMBDA_START {
        let args = [expr, read_expression_function_call_end(code)?]

        let inst = code.add_fun_call(span, "", "call", args, type_args)
        ret found(inst.id)
    }

    if type_args.len() > 0 {
        report_error("Type arguments are not allowed here", span)
    }

    ret found(expr)
}

fun Parser.read_expression_with_name(code: NCode): Parsed<NInstId> {
    let span = lexer.current_token_span
    let path = read_module_path()?
    let name = read_name()?
    let type_args = []

    if lexer.current_token_kind == TokenKind::LTH {
        type_args = read_type_param_args()?
    }

    // Function call:
    // modulePath? anyName callSuffix
    if lexer.current_token_kind == TokenKind::LPAREN {
        let args = read_expression_function_call_params(code)?

        if lexer.current_token_kind == TokenKind::LAMBDA_START {
            args[] = read_expression_function_call_end(code)?
        }

        let inst = code.add_fun_call(span, path, name, args, type_args)
        ret found(inst.id)
    }

    if lexer.current_token_kind == TokenKind::LAMBDA_START {
        let args = [read_expression_function_call_end(code)?]

        let inst = code.add_fun_call(span, path, name, args, type_args)
        ret found(inst.id)
    }

    // New instance:
    // modulePath? anyName typeParamArg? newInstance
    // modulePath? anyName typeParamArg? newInstance callSuffix
    if lexer.current_token_kind == TokenKind::STRUCT_START {
        let expr = read_expression_new_instance(code, path, name, type_args)?
        ret read_expression_call_suffix(code, expr)
    }

    // String template
    // modulePath? anyName typeParamArg? PLAIN_STRING
    // modulePath? anyName typeParamArg? STRING_START stringContents* STRING_END
    if lexer.current_token_kind == TokenKind::PLAIN_STRING || lexer.current_token_kind == TokenKind::STRING_START {
        if type_args.len() > 0 {
            report_error("Type arguments are not allowed here", span)
        }

        ret read_expression_string_template(code, name, path)
    }

    // Variable:
    // modulePath? anyName
    if type_args.len() > 0 {
        report_error("Type arguments are not allowed here", span)
    }
    
    let inst = code.add_load_var(span, path, name, None())
    ret found(inst.id)
}

fun Parser.read_expression_new_instance(code: NCode, path: String, name: String, type_args: List<NTypeUsage>): Parsed<NInstId> {
    let span = lexer.current_token_span
    skip_token_kind(TokenKind::STRUCT_START)?
    skip_nl()

    let type_usage = NTypeUsage::simple_with_path(path, name)
    type_usage.type_params = type_args
    let instance = code.add_alloc(span, type_usage)

    read_until_delimited(TokenKind::RBRACKET) @{
        let span = lexer.current_token_span
        let path = read_module_path()?
        let name = read_name()?

        if lexer.current_token_kind == TokenKind::COLON {
            skip_token_kind(TokenKind::COLON)?
            skip_nl()
            let expr = read_expression(code)?

            code.add_store_field(span, instance.id, name, expr)
        } else {
            let inst = code.add_load_var(span, path, name, None())

            code.add_store_field(span, instance.id, name, inst.id)
        }

        ret found(nothing)
    }?

    let inst = code.add_link(span, instance.id)
    ret found(inst.id)
}

fun Parser.read_expression_function_call_params(code: NCode): Parsed<List<NInstId>> {
    let span = lexer.current_token_span
    skip_token_kind(TokenKind::LPAREN)?
    skip_nl()
    let args = []

    read_until_delimited_by(TokenKind::COMMA, TokenKind::RPAREN) @{
        args[] = read_expression(code)?
        ret found(nothing)
    }?

    ret found(args)
}

fun Parser.read_expression_function_call_end(code: NCode): Parsed<NInstId> {
    ret read_expression_lambda(code)
}

fun Parser.read_expression_string_template(code: NCode, name: String, path: String): Parsed<NInstId> {
    let span = lexer.current_token_span

    if lexer.current_token_kind == TokenKind::PLAIN_STRING {
        let expr = read_expression_string(code)?
        let list = code.add_fun_call(span, "List", "new", [], [NTypeUsage::simple("String")])
        code.add_fun_call(span, "", "add", [expr], [])

        let inst = code.add_fun_call(span, path, name, [list.id], [])
        ret found(inst.id)
    }

    let list = code.add_fun_call(span, "List", "new", [], [NTypeUsage::simple("String")]).id
    let args = [list]
    let prev_is_string = false

    skip_token_kind(TokenKind::STRING_START)?

    loop {
        if lexer.current_token_kind == TokenKind::STRING_BLOB {
            let text = lexer.current_token_text
            lexer.next_token()

            let new_string = code.add_lit_string(span, text).id
            code.add_fun_call(span, "", "add", [list, new_string], [])
            prev_is_string = true
            continue
        }

        if lexer.current_token_kind == TokenKind::STRING_VAR {
            if !prev_is_string {
                let new_string = code.add_lit_string(span, "").id
                code.add_fun_call(span, "", "add", [list, new_string], [])
            }
            let variable_name = lexer.current_token_text
            lexer.next_token()

            let load_var = code.add_load_var(span, "", variable_name, None())
            args[] = load_var.id
            prev_is_string = false
            continue
        }

        if lexer.current_token_kind == TokenKind::STRING_INTERP_START {
            if !prev_is_string {
                let new_string = code.add_lit_string(span, "").id
                code.add_fun_call(span, "", "add", [list, new_string], [])
            }
            lexer.next_token()
            let expr = read_expression(code)?
            skip_token_kind(TokenKind::STRING_INTERP_END)?
            args[] = expr
            prev_is_string = false
            continue
        }

        skip_token_kind(TokenKind::STRING_END)?
        break
    }

    let inst = code.add_fun_call(span, path, name, args, [])
    ret found(inst.id)
}
