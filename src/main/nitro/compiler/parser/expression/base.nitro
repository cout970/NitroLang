
// expressionBase
//     : parenthesizedExpression
//     | parenthesizedExpression callSuffix
//     | constExpr
//     | constExpr callSuffix
//     | string
//     | string callSuffix
//     | listExpr
//     | mapExpr
//     | setExpr
//     | lambdaExpr
//     | THIS
//     | THIS callSuffix
//     | modulePath? anyName
//     | modulePath? anyName expressionAssignmentEnd
//     | modulePath? anyName callSuffix
//     | modulePath? anyName typeParamArg? newInstance
//     | modulePath? anyName typeParamArg? newInstance callSuffix
//     | modulePath? anyName typeParamArg? STRING_START stringContents* STRING_END
//     | modulePath? anyName typeParamArg? PLAIN_STRING
//     | sizeOfExpr
//     | jsonExpr
//     | BREAK
//     | CONTINUE
//     ;

// callSuffix
//     : typeParamArg? functionCallParams functionCallEnd?
//     : typeParamArg? functionCallEnd
//     ;

// newInstance
//     : STRUCT_START NL* (newInstanceEntry (commaOrNl newInstanceEntry)* COMMA?)? NL* RBRACKET ;

// newInstanceEntry
//     : modulePath? anyName COLON NL* expression
//     | modulePath? anyName
//     ;

// functionCallParams
//     : LPAREN NL* functionCallParamList? RPAREN ;

// functionCallParamList
//     : expression (commaOrNl expression)* COMMA? NL* ;

// functionCallEnd
//     : lambdaExpr ;

// E.g. a = 0
// E.g. i += 1
// expressionAssignmentEnd
//     : ASSIGN NL* expression
//     | ADD_ASSIGN NL* expression
//     | SUB_ASSIGN NL* expression
//     | MUL_ASSIGN NL* expression
//     | DIV_ASSIGN NL* expression
//     | MOD_ASSIGN NL* expression
//     ;

fun Parser.read_expression_base(code: NCode): Parsed<NInstId> {
    let span = lexer.current_token_span

    let inst = when lexer.current_token_kind {
        // parenthesizedExpression
        // parenthesizedExpression callSuffix
        TokenKind::LPAREN -> read_expression_in_parens(code)
        // constExpr
        // constExpr callSuffix
        TokenKind::INT_NUMBER -> read_expression_nvalue(code)
        TokenKind::LONG_NUMBER -> read_expression_nvalue(code)
        TokenKind::FLOAT_NUMBER -> read_expression_nvalue(code)
        TokenKind::PLAIN_STRING -> read_expression_nvalue(code)
        TokenKind::ASCII_STRING -> read_expression_nvalue(code)
        TokenKind::UNICODE_STRING -> read_expression_nvalue(code)
        TokenKind::TRUE -> read_expression_nvalue(code)
        TokenKind::FALSE -> read_expression_nvalue(code)
        TokenKind::NULL -> read_expression_nvalue(code)
        TokenKind::NOTHING -> read_expression_nvalue(code)
        // string
        // string callSuffix
        TokenKind::PLAIN_STRING -> read_expression_string_or_call(code)
        TokenKind::STRING_START -> read_expression_string_or_call(code)
        TokenKind::STRING2_START -> read_expression_string_or_call(code)
        // THIS
        // THIS callSuffix
        TokenKind::THIS -> read_expression_this(code)
        // modulePath? anyName
        // modulePath? anyName expressionAssignmentEnd
        // modulePath? anyName callSuffix
        // modulePath? anyName typeParamArg? newInstance
        // modulePath? anyName typeParamArg? newInstance callSuffix
        // modulePath? anyName typeParamArg? STRING_START stringContents* STRING_END
        // modulePath? anyName typeParamArg? PLAIN_STRING
        TokenKind::IDENTIFIER -> read_expression_with_name(code)
        // listExpr
        TokenKind::LBRACKET -> read_expression_list(code)
        // mapExpr
        TokenKind::MAP_START -> read_expression_map(code)
        // setExpr
        TokenKind::SET_START -> read_expression_set(code)
        // lambdaExpr
        TokenKind::LAMBDA_START -> read_expression_lambda(code)
        // sizeOfExpr
        TokenKind::SIZE_OF -> read_expression_size_of(code)
        // jsonExpr
        TokenKind::JSON -> read_expression_json(code)
        // includeAsBytes
        TokenKind::INCLUDE_AS_BYTES -> read_expression_include_as_bytes(code)
        // includeAsString
        TokenKind::INCLUDE_AS_STRING -> read_expression_include_as_string(code)
        // BREAK
        TokenKind::BREAK -> read_expression_break(code)
        // CONTINUE
        TokenKind::CONTINUE -> read_expression_continue(code)

        else -> {
            ret parse_error(ParseError::ExpectedExpression, lexer.current_token)
        }
    }

    ret inst
}

fun Parser.read_expression_in_parens(code: NCode): Parsed<NInstId> {
    skip_token_kind(TokenKind::LPAREN)?
    skip_nl()
    let expr = read_expression(code)?
    skip_nl()
    skip_token_kind(TokenKind::RPAREN)?
    ret read_expression_call_suffix(code, expr)
}

fun Parser.read_expression_nvalue(code: NCode): Parsed<NInstId> {
    let expr = read_expression_literal(code)?
    ret read_expression_call_suffix(code, expr)
}

fun Parser.read_expression_string_or_call(code: NCode): Parsed<NInstId> {
    let expr = read_expression_string(code)?
    ret read_expression_call_suffix(code, expr)
}

fun Parser.read_expression_this(code: NCode): Parsed<NInstId> {
    let span = lexer.current_token_span
    skip_token_kind(TokenKind::THIS)?

    let inst = code.add_load_var(span, "", "this", None())
    ret read_expression_call_suffix(code, inst.id)
}

fun Parser.read_expression_call_suffix(code: NCode, expr: NInstId): Parsed<NInstId> {
    let span = lexer.current_token_span
    let type_args = try_read_type_param_args()

    // typeParamArg? functionCallParams functionCallEnd?
    if lexer.current_token_kind == TokenKind::LPAREN {
        let span = lexer.current_token_span
        let args = read_expression_function_call_params(code)?
        args.add_first(expr)

        if lexer.current_token_kind == TokenKind::LAMBDA_START {
            args[] = read_expression_function_call_end(code)?
        }

        let inst = code.add_fun_call(span, "", "call", true, args, type_args)
        ret found(inst.id)
    }

    // typeParamArg? functionCallEnd
    if lexer.current_token_kind == TokenKind::LAMBDA_START {
        let args = [expr, read_expression_function_call_end(code)?]

        let inst = code.add_fun_call(span, "", "call", true, args, type_args)
        ret found(inst.id)
    }

    if type_args.len > 0 {
        report_error("Type arguments are not allowed here", span)
    }

    ret found(expr)
}

fun Parser.try_read_type_param_args(): List<NTypeUsage> {
    // find_token_kind_before2() is required to distinguish between a function call and a comparison
    // i.e. `a < b` could be the beginning of a function call `a < b >()`, or a comparison `a < b + 1`
    if lexer.current_token_kind == TokenKind::LTH && lexer.find_token_kind_before2(TokenKind::GTH, [TokenKind::LPAREN, TokenKind::LBRACKET, TokenKind::LBRACE, TokenKind::NL]) {
        let save_tk = lexer.tk
        let res = read_type_param_args()

        if res is Parsed::Found<*> {
            ret res!!
        } else {
            lexer.tk = save_tk
        }
    }
    ret []
}

fun Parser.read_expression_with_name(code: NCode): Parsed<NInstId> {
    let span = lexer.current_token_span
    let path = read_module_path()?
    let name = read_name()?
    let type_args = try_read_type_param_args()

    // Function call:
    // modulePath? anyName callSuffix
    if lexer.current_token_kind == TokenKind::LPAREN {
        let args = read_expression_function_call_params(code)?

        if lexer.current_token_kind == TokenKind::LAMBDA_START {
            args[] = read_expression_function_call_end(code)?
        }

        let inst = code.add_fun_call(span, path, name, false, args, type_args)
        ret found(inst.id)
    }

    if lexer.current_token_kind == TokenKind::LAMBDA_START {
        let args = [read_expression_function_call_end(code)?]

        let inst = code.add_fun_call(span, path, name, false, args, type_args)
        ret found(inst.id)
    }

    // New instance:
    // modulePath? anyName typeParamArg? newInstance
    // modulePath? anyName typeParamArg? newInstance callSuffix
    if lexer.current_token_kind == TokenKind::STRUCT_START {
        let expr = read_expression_new_instance(code, path, name, type_args)?
        ret read_expression_call_suffix(code, expr)
    }

    // String template
    // modulePath? anyName typeParamArg? PLAIN_STRING
    // modulePath? anyName typeParamArg? STRING_START stringContents* STRING_END
    if lexer.current_token_kind == TokenKind::PLAIN_STRING || lexer.current_token_kind == TokenKind::STRING_START {
        if type_args.len > 0 {
            report_error("Type arguments are not allowed here", span)
        }

        ret read_expression_string_template(code, name, path)
    }

    if allow_expression_assignment && lexer.current_token_kind == TokenKind::ASSIGN || lexer.current_token_kind == TokenKind::ADD_ASSIGN || lexer.current_token_kind == TokenKind::SUB_ASSIGN || lexer.current_token_kind == TokenKind::MUL_ASSIGN || lexer.current_token_kind == TokenKind::DIV_ASSIGN || lexer.current_token_kind == TokenKind::MOD_ASSIGN {
        if type_args.len > 0 {
            report_error("Type arguments are not allowed here", span)
        }

        ret read_expression_name_assignment(code, path, name)
    }

    // Variable:
    // modulePath? anyName
    if type_args.len > 0 {
        report_error("Type arguments are not allowed here", span)
    }

    let inst = code.add_load_var(span, path, name, None())
    ret found(inst.id)
}

fun Parser.read_expression_name_assignment(code: NCode, path: String, name: String): Parsed<NInstId> {
    let span = lexer.current_token_span

    if lexer.current_token_kind == TokenKind::ASSIGN {
        lexer.next_token()
        skip_nl()
        let value = read_expression(code)?

        code.add_store_var(span, path, name, value, None())
        let inst = code.add_lit_nothing(span)
        ret found(inst.id)
    }

    let operator = when lexer.current_token_kind {
        TokenKind::ADD_ASSIGN -> BinaryOperator::ADD
        TokenKind::SUB_ASSIGN -> BinaryOperator::SUB
        TokenKind::MUL_ASSIGN -> BinaryOperator::MUL
        TokenKind::DIV_ASSIGN -> BinaryOperator::DIV
        TokenKind::MOD_ASSIGN -> BinaryOperator::MOD
        else -> unreachable()
    }
    lexer.next_token()
    skip_nl()

    let left_id = code.add_load_var(span, path, name, None()).id
    let right_id = read_expression(code)?

    let result = if operator.uses_ordering {
        let get_ordering = code.add_fun_call(span, "", "get_ordering", true, [left_id, right_id], [])
        code.add_fun_call(span, "", operator.method, true, [get_ordering.id], []).id
    } else {
        code.add_fun_call(span, "", operator.method, true, [left_id, right_id], []).id
    }

    code.add_store_var(span, path, name, result, None())

    let inst = code.add_lit_nothing(span)
    ret found(inst.id)
}

fun Parser.read_expression_new_instance(code: NCode, path: String, name: String, type_args: List<NTypeUsage>): Parsed<NInstId> {
    let span = lexer.current_token_span
    skip_token_kind(TokenKind::STRUCT_START)?
    skip_nl()

    let type_usage = NTypeUsage::simple_with_path(span, path, name)
    type_usage.params = type_args
    let instance = code.add_alloc(span, type_usage)

    read_until_delimited(TokenKind::RBRACKET) @{
        let span = lexer.current_token_span
        let path = read_module_path()?
        let name = read_name()?

        if lexer.current_token_kind == TokenKind::COLON {
            skip_token_kind(TokenKind::COLON)?
            skip_nl()
            let expr = read_expression(code)?

            code.add_init_field(span, instance.id, name, expr)
        } else {
            let inst = code.add_load_var(span, path, name, None())

            code.add_init_field(span, instance.id, name, inst.id)
        }

        ret found(nothing)
    }?

    let inst = code.add_link(span, instance.id)
    ret found(inst.id)
}

fun Parser.read_expression_function_call_params(code: NCode): Parsed<List<NInstId>> {
    let span = lexer.current_token_span
    skip_token_kind(TokenKind::LPAREN)?
    skip_nl()
    let args = []

    read_until_delimited(TokenKind::RPAREN) @{
        args[] = read_expression(code)?
        ret found(nothing)
    }?

    ret found(args)
}

fun Parser.read_expression_function_call_end(code: NCode): Parsed<NInstId> {
    ret read_expression_lambda(code)
}

fun Parser.read_expression_string_template(code: NCode, name: String, path: String): Parsed<NInstId> {
    let span = lexer.current_token_span

    if lexer.current_token_kind == TokenKind::PLAIN_STRING {
        let expr = read_expression_string(code)?
        let list = code.add_fun_call(span, "List", "new", false, [], [NTypeUsage::simple(span, "String")])
        code.add_fun_call(span, "", "add", true, [list.id, expr], [])

        let inst = code.add_fun_call(span, path, name, false, [list.id], [])
        ret found(inst.id)
    }

    let list = code.add_fun_call(span, "List", "new", false, [], [NTypeUsage::simple(span, "String")]).id
    let args = [list]
    let prev_is_string = false

    skip_token_kind(TokenKind::STRING_START)?

    loop {
        if lexer.current_token_kind == TokenKind::STRING_BLOB {
            let text = lexer.current_token_text
            lexer.next_token()

            let new_string = code.add_lit_string(span, text).id
            code.add_fun_call(span, "", "add", true, [list, new_string], [])
            prev_is_string = true
            continue
        }

        if lexer.current_token_kind == TokenKind::STRING_VAR {
            if !prev_is_string {
                let new_string = code.add_lit_string(span, "").id
                code.add_fun_call(span, "", "add", true, [list, new_string], [])
            }
            let variable_name = lexer.current_token_text
            lexer.next_token()

            let load_var = code.add_load_var(span, "", variable_name, None())
            args[] = load_var.id
            prev_is_string = false
            continue
        }

        if lexer.current_token_kind == TokenKind::STRING_INTERP_START {
            if !prev_is_string {
                let new_string = code.add_lit_string(span, "").id
                code.add_fun_call(span, "", "add", true, [list, new_string], [])
            }
            lexer.next_token()
            let expr = read_expression(code)?
            skip_token_kind(TokenKind::STRING_INTERP_END)?
            args[] = expr
            prev_is_string = false
            continue
        }

        skip_token_kind(TokenKind::STRING_END)?
        break
    }

    let inst = code.add_fun_call(span, path, name, false, args, [])
    ret found(inst.id)
}
