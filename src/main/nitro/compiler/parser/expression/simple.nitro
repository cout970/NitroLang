
// E.g. var as Int
// E.g. var is Int
// E.g. var !is Int
// E.g. var in %[1, 2, 3]
// E.g. var !in %[1, 2, 3]
// E.g. not var
// E.g. -var
// expressionSimple
//     : expressionWithSuffix AS typeUsage
//     | expressionWithSuffix IS typePattern
//     | expressionWithSuffix NOT IS typePattern
//     | expressionWithSuffix IN expressionWithSuffix
//     | expressionWithSuffix NOT IN expressionWithSuffix
//     | expressionWithSuffix
//     | notExpr
//     | minusExpr
//     | plusExpr
//     ;

fun Parser.read_expression_simple(code: NCode): Parsed<NInstId> {
    let span = lexer.current_token_span

    if lexer.current_token_kind == TokenKind::NOT {
        lexer.next_token()
        let expr = read_expression_simple(code)?

        let call = code.add_fun_call(span, "", "logical_not", true, [expr], [])
        ret found(call.id)
    }

    if lexer.current_token_kind == TokenKind::SUB {
        lexer.next_token()
        let expr = read_expression_simple(code)?

        let call = code.add_fun_call(span, "", "unary_minus", true, [expr], [])
        ret found(call.id)
    }

    if lexer.current_token_kind == TokenKind::ADD {
        lexer.next_token()
        let expr = read_expression_simple(code)?

        let call = code.add_fun_call(span, "", "unary_plus", true, [expr], [])
        ret found(call.id)
    }

    let left = read_expression_with_suffix(code)?

    if lexer.current_token_kind == TokenKind::AS {
        lexer.next_token()
        let type_usage = read_type_usage()?

        let inst = code.add_as_type(span, left, type_usage)
        ret found(inst.id)
    }

    if lexer.current_token_kind == TokenKind::IS {
        lexer.next_token()

        let type_pattern = read_type_pattern()?
        let inst = code.add_is_type(span, left, type_pattern)

        ret found(inst.id)
    }

    if lexer.current_token_kind == TokenKind::IN {
        lexer.next_token()

        let right = read_expression_with_suffix(code)?
        let inst = code.add_fun_call(span, "", "contains", true, [right, left], [])

        ret found(inst.id)
    }

     if lexer.current_token_kind == TokenKind::NOT {
        lexer.next_token()

        if lexer.current_token_kind == TokenKind::IS {
            lexer.next_token()

            let type_pattern = read_type_pattern()?
            let inst = code.add_is_type(span, left, type_pattern)

            inst = code.add_fun_call(span, "", "logical_not", true, [inst.id], [])

            ret found(inst.id)
        }

        if lexer.current_token_kind == TokenKind::IN {
            lexer.next_token()

            let right = read_expression_with_suffix(code)?
            let inst = code.add_fun_call(span, "", "contains", true, [right, left], [])

            inst = code.add_fun_call(span, "", "logical_not", true, [inst.id], [])

            ret found(inst.id)
        }

        ret parse_error_expected(ParseError::ExpectedToken, lexer.current_token, TokenKind::IS)
     }

    ret found(left)
}
