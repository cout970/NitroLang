
// Read an specific token
fun Parser.skip_token_kind(tk: TokenKind): Parsed<Nothing> {
    if lexer.current_token_kind != tk {
        lexer.print_debug_info()

        ret parse_error_expected(ParseError::ExpectedToken, lexer.current_token, tk)
    }

    lexer.next_token()
    ret found(nothing)
}

// Discard a token if encountered
fun Parser.ignore_token_kind(tk: TokenKind) {
    if lexer.current_token_kind == tk {
        lexer.next_token()
    }
}

// Read an identifier, lower case or upper case
fun Parser.read_name(): Parsed<String> {
    if lexer.current_token_kind != TokenKind::IDENTIFIER  {
        ret parse_error(ParseError::ExpectedIdentifier, lexer.current_token)
    }

    let name = lexer.current_token_text
    lexer.next_token()
    ret found(name)
}

// Read a module path like `foo::bar` in `foo::bar::Int`,
// will return an empty string if no module path is found, for example if there is a single identifier without `::` after it.
fun Parser.read_module_path(): Parsed<String> {
    // modulePath
    //      : (anyName DOUBLE_COLON)+ ;
    let path: String = ""
    let first = true

    if lexer.current_token_kind != TokenKind::IDENTIFIER {
        ret found(path)
    }

    while lexer.next_token_kind == TokenKind::DOUBLE_COLON {
        if !first {
            path = path.concat("::")
        }
        first = false

        let name: String = read_name()?
        path += name
        skip_token_kind(TokenKind::DOUBLE_COLON)?
    }

    ret found(path)
}

fun Parser.read_module_path_with_params(generic_params: List<NTypeUsage>): Parsed<String> {
    // modulePath
    //      : (anyName DOUBLE_COLON)+
    //      | (anyName type_param_args DOUBLE_COLON)+;

    let path: String = ""
    let first = true

    while lexer.current_token_kind == TokenKind::IDENTIFIER {
        let save = lexer.save_state()
        let name: String = read_name()?

        // anyName type_param_args ::
        if lexer.current_token_kind == TokenKind::LTH {
            let params: List<NTypeUsage> = try_read_type_param_args()

            if params.is_not_empty() && lexer.current_token_kind == TokenKind::DOUBLE_COLON {
                if !first {
                    path = path.concat("::")
                }
                first = false
                path += name
                generic_params.add_all(params)
                skip_token_kind(TokenKind::DOUBLE_COLON)?
            } else {
                // No DOUBLE_COLON, end of the loop
                lexer.restore_state(save)
                break
            }
            continue
        }

        // anyName DOUBLE_COLON
        if lexer.current_token_kind == TokenKind::DOUBLE_COLON {
            if !first {
                path = path.concat("::")
            }
            first = false
            path += name
            skip_token_kind(TokenKind::DOUBLE_COLON)?
            continue
        }

        // No DOUBLE_COLON, end of the loop
        lexer.restore_state(save)
        break
    }

    ret found(path)
}

// Reads a module path, but also includes the path of the modules enclosing this declaration
// i.e `mod A { mod B { struct C::MyStruct {} }  }` will return "A::B::C::MyStruct" when parsing the struct
fun Parser.read_declaration_module_path(): Parsed<String> {
    let path = read_module_path()?

    if module_path_stack.is_empty()  {
        ret found(path)
    }

    let enclosing = module_path_stack.join("::")

    if path.is_empty() {
        ret found(enclosing)
    }

    ret found(Path::join(enclosing, path))
}

// Given a module path and a name, returns the full path, i.e `foo::bar` and `Int` will return `foo::bar::Int`
fun Path::join(path: String, name: String): String {
  if path.is_empty() {
      ret name
  }

  ret "$path::$name"
}

// Read a plain string, e.g. "hello world"
fun Parser.read_plain_string(): Parsed<String> {
    if lexer.current_token_kind != TokenKind::PLAIN_STRING {
        ret parse_error(ParseError::ExpectedPlainString, lexer.current_token)
    }

    let name = lexer.current_token_text
    lexer.next_token()
    ret found(name)
}

// Read a ascii string, e.g. a"A" or a"B"
fun Parser.read_ascii_string(): Parsed<Int> {
    if lexer.current_token_kind != TokenKind::ASCII_STRING {
        ret parse_error(ParseError::ExpectedPlainString, lexer.current_token)
    }

    let ascii = lexer.current_token_text
    lexer.next_token()
    ret found(ascii.to_int_in_base(10)!!)
}

fun Parser.read_unicode_string(): Parsed<Char> {
    if lexer.current_token_kind != TokenKind::UNICODE_STRING {
        ret parse_error(ParseError::ExpectedPlainString, lexer.current_token)
    }

    let string = lexer.current_token_text
    lexer.next_token()
    ret found(string.get_codepoint(0)!!)
}

// Ignore next newlines
fun Parser.skip_nl() {
    while lexer.current_token_kind == TokenKind::NL {
        lexer.next_token()
    }
}

// Ignores a comma if encountered
fun Parser.skip_comma() {
    if lexer.current_token_kind == TokenKind::COMMA {
        lexer.next_token()
    }
}

// Skip comma and new newlines, must contain at least one newline or a comma
fun Parser.read_comma_or_nl(): Parsed<Nothing> {
//    commaOrNl
//        : COMMA NL*
//        | NL+
//        ;

    if lexer.current_token_kind == TokenKind::COMMA {
        lexer.next_token()
        skip_nl()
        ret found(nothing)
    }

    if lexer.current_token_kind == TokenKind::NL {
        // At least one NL
        lexer.next_token()
        skip_nl()
        ret found(nothing)
    }

    ret parse_error(ParseError::ExpectedComma, lexer.current_token)
}

fun Parser.read_until_delimited(tk: TokenKind, lambda: Parser.() -> Parsed<Nothing>): Parsed<Nothing> {
    while lexer.current_token_kind != tk {
        if !has_remaining_tokens() {
            ret parse_error(ParseError::ReachedEnd, lexer.current_token)
        }

        let res: Parsed<Nothing> = lambda(this)
        if res.is_error() {
            ret res
        }

        if lexer.current_token_kind == TokenKind::COMMA {
            lexer.next_token()
            skip_nl()
            continue
        }

        if lexer.current_token_kind == TokenKind::NL {
            // At least one NL
            lexer.next_token()
            skip_nl()
            continue
        }

        // No delimiter, end of the loop
        break
    }

    skip_token_kind(tk)?

    ret found(nothing)
}

fun Parser.read_until_delimited_by(sep: TokenKind, end: TokenKind, lambda: Parser.() -> Parsed<Nothing>): Parsed<Nothing> {
    while lexer.current_token_kind != end {
        if !has_remaining_tokens() {
            ret parse_error(ParseError::ReachedEnd, lexer.current_token)
        }

        let res: Parsed<Nothing> = lambda(this)
        if res.is_error() {
            ret res
        }

        if lexer.current_token_kind != sep {
            break
        }

        lexer.next_token()
        skip_nl()
    }

    skip_token_kind(end)?

    ret found(nothing)
}

// Checks if there are remaining tokens, otherwise we reached the end of the file
fun Parser.has_remaining_tokens(): Boolean = lexer.current_token_kind != TokenKind::EOF

fun Parser.recover_from_error() {
    // Skip until NL or EOF
    while lexer.current_token_kind != TokenKind::NL && has_remaining_tokens() {
        lexer.next_token()
    }
}

fun Parser.report_error(msg: String, span: Span) {
    reporter.report_error(msg, span)
}

fun Parser.report_warning(msg: String, span: Span) {
    reporter.report_warning(msg, span)
}

fun Parser.declare_name(name: String, span: Span) {
    if name in program.declared_names {
        let prev_location = program.declared_names[name]!!
        reporter.report_error("Name '$name' defined at $span, was already defined at $prev_location", span)
    }

    program.declared_names[name] = span
}

fun Parser.start_generics_collection(generics: NGenericParams, source: NGenericSource) {
    if current_generics.definitions.is_not_empty() {
        crash("Generics where collected outside of a type definition: ${current_generics.definitions}")
    }
    current_generics = generics
    current_generics.source = source
    allow_generics_collection = true
}

fun Parser.stop_generics_collection() {
    allow_generics_collection = false
    current_generics = NGenericParams::new(NGenericSource::Invalid)
}
