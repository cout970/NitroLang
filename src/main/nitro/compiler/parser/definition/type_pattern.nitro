
// typePattern
//     : THIS_TYPE
//     | LTH NL* typePattern NL* GTH
//     | baseTypePattern
//     | baseTypePattern DOT functionTypePattern
//     | functionTypePattern
//     | typeParameter
//     | MUL
//     ;
//
// baseTypePattern
//     : modulePath? anyName typePatternArgs? ;
//
// functionTypePattern
//       : LPAREN RPAREN ARROW typePattern
//       | LPAREN functionTypePatternParam (commaOrNl functionTypePatternParam)* RPAREN ARROW typePattern
//       ;
//
// functionTypePatternParam
//       : typePattern
//       | anyName COLON typePattern
//       ;
//
// typePatternArgs
//     : LTH NL* typePattern (commaOrNl typePattern)* COMMA? NL* GTH ;
//

struct NTypePattern {
    span: Span
    kind: TypePatternKind
    name: String
    path: String
    params: List<NTypePattern>
    resolved: Optional<ResolvedTypePattern>
}

enum TypePatternKind {
    TYPE_SIMPLE,
    TYPE_PARAM,
    TYPE_ANY,
}

fun Parser.read_type_pattern(): Parsed<NTypePattern> {
    let span = lexer.current_token_span

    // Any
    if lexer.current_token_kind == TokenKind::MUL {
        lexer.next_token()
        ret found(NTypePattern @[
            span,
            kind: TypePatternKind::TYPE_ANY,
            name: "*",
            path: "",
            params: [],
            resolved: None(),
        ])
    }

    // #A
    if lexer.current_token_kind == TokenKind::HASH {
        lexer.next_token()
        let name: String = read_name()?

        ret found(NTypePattern @[
            span,
            kind: TypePatternKind::TYPE_PARAM,
            name,
            path: "",
            params: [],
            resolved: None(),
        ])
    }

    // (Int, Boolean) -> Float
    if lexer.current_token_kind == TokenKind::LPAREN {
        ret read_function_type_pattern(None(), span)
    }

    // <T>
    if lexer.current_token_kind == TokenKind::LTH {
        lexer.next_token()

        skip_nl()
        let type_pattern = read_type_pattern()?
        skip_nl()

        skip_token_kind(TokenKind::GTH)?

        ret found(type_pattern)
    }

    // core::Int, List<Int>
    let path: String = read_module_path()?
    let name: String = read_name()?
    let params: List<NTypePattern> = []

    if lexer.current_token_kind == TokenKind::LTH {
        params = read_type_pattern_param_args()?
    }

    let ty = NTypePattern @[
        span,
        kind: TypePatternKind::TYPE_SIMPLE,
        name,
        path,
        params,
        resolved: None(),
    ]

    if lexer.current_token_kind != TokenKind::DOT {
        ret found(ty)
    }

    // Skip dot
    lexer.next_token()

    // Int.() -> Nothing
    ret read_function_type_pattern(Some(ty), span)
}

// <A, B, C>
fun Parser.read_type_pattern_param_args(): Parsed<List<NTypePattern>> {
    let list: List<NTypePattern> = []
    skip_token_kind(TokenKind::LTH)?

    skip_nl()
    read_until_delimited(TokenKind::GTH) @{
        list[] = read_type_pattern()?
        ret found(nothing)
    }?

    ret found(list)
}

// (Int, Boolean)->Float
fun Parser.read_function_type_pattern(arg1: Optional<NTypePattern>, span: Span): Parsed<NTypePattern> {
    // // (Int) -> Int
    // functionTypePattern
    //       : LPAREN RPAREN ARROW typePattern
    //       | LPAREN functionTypePatternParam (commaOrNl functionTypePatternParam)* RPAREN ARROW typePattern
    //       ;
    let params = []

    if arg1.is_some() {
        params[] = arg1!!
    }

    skip_token_kind(TokenKind::LPAREN)?
    skip_nl()
    read_until_delimited(TokenKind::RPAREN) @{
        lexer.next_token()
        params[] = read_function_type_pattern_param()?
        ret found(nothing)
    }?

    skip_token_kind(TokenKind::RPAREN)?
    skip_token_kind(TokenKind::ARROW)?

    params[] = read_type_pattern()?

    ret found(NTypePattern @[
        span,
        kind: TypePatternKind::TYPE_SIMPLE,
        name: "Function",
        path: "",
        params,
        resolved: None(),
    ])
}

fun Parser.read_function_type_pattern_param(): Parsed<NTypePattern> {
    // // a, a: Int
    // functionTypePatternParam
    //       : typePattern
    //       | anyName COLON typePattern
    //       ;

    // Skip name, is only for documentation
    if lexer.next_token_kind == TokenKind::COLON {
        let name: String = read_name()?
        skip_token_kind(TokenKind::COLON)?
    }

    ret read_type_pattern()
}

fun NTypePattern.get_ordering(other: NTypePattern): Ordering {
    ret (kind <=> other.kind).with(name <=> other.name).with(path <=> other.path)
}

fun NTypePattern.get_hash(): Int {
    let hash = kind.variant
    hash = (hash * 31) + name.get_hash()
    hash = (hash * 31) + path.get_hash()
    ret hash
}

fun TypePatternKind.is_equal(other: TypePatternKind): Boolean = this.variant == other.variant

fun NTypePattern.to_string(): String {
    let s = ""

    if kind == TypePatternKind::TYPE_PARAM {
        ret "#$name"
    }

    if kind == TypePatternKind::TYPE_ANY {
        ret this.name
    }

    if path != "" {
        s = path + "::"
    }

    s = s + name

    if params.len > 0 {
        s = s + "<"
        repeat params.len {
            s += params[it]!!.to_string()
            if it < limit - 1 {
                s += ", "
            }
        }
        s = s + ">"
    }

    ret s
}