
// typePattern
//     : THIS_TYPE
//     | LTH NL* typePattern NL* GTH
//     | baseTypePattern
//     | baseTypePattern DOT functionTypePattern
//     | functionTypePattern
//     | typeParameter
//     | MUL
//     ;
//
// baseTypePattern
//     : modulePath? anyName typePatternArgs? ;
//
// functionTypePattern
//       : LPAREN RPAREN ARROW typePattern
//       | LPAREN functionTypePatternParam (commaOrNl functionTypePatternParam)* RPAREN ARROW typePattern
//       ;
//
// functionTypePatternParam
//       : typePattern
//       | anyName COLON typePattern
//       ;
//
// typePatternArgs
//     : LTH NL* typePattern (commaOrNl typePattern)* COMMA? NL* GTH ;
//

fun Parser.read_type_pattern(): Parsed<NTypePattern> {
    let span = lexer.current_token_span

    // Any
    if lexer.current_token_kind == TokenKind::MUL {
        lexer.next_token()
        ret found(NTypePattern @[
            span,
            kind: TypePatternKind::TYPE_ANY,
            name: "*",
            path: "",
            params: [],
            resolved: None(),
        ])
    }

    // #A
    if lexer.current_token_kind == TokenKind::HASH {
        lexer.next_token()
        let name: String = read_name()?

        ret found(NTypePattern @[
            span,
            kind: TypePatternKind::TYPE_PARAM,
            name,
            path: "",
            params: [],
            resolved: None(),
        ])
    }

    // (Int, Boolean) -> Float
    if lexer.current_token_kind == TokenKind::LPAREN {
        ret read_function_type_pattern(None(), span)
    }

    // <T>
    if lexer.current_token_kind == TokenKind::LTH {
        lexer.next_token()

        skip_nl()
        let type_pattern = read_type_pattern()?
        skip_nl()

        skip_token_kind(TokenKind::GTH)?

        ret found(type_pattern)
    }

    // core::Int, List<Int>
    let path: String = read_module_path()?
    let name: String = read_name()?
    let params: List<NTypePattern> = []

    if lexer.current_token_kind == TokenKind::LTH {
        params = read_type_pattern_param_args()?
    }

    let ty = NTypePattern @[
        span,
        kind: TypePatternKind::TYPE_SIMPLE,
        name,
        path,
        params,
        resolved: None(),
    ]

    if lexer.current_token_kind != TokenKind::DOT {
        ret found(ty)
    }

    // Skip dot
    lexer.next_token()

    // Int.() -> Nothing
    ret read_function_type_pattern(Some(ty), span)
}


fun Parser.read_type_pattern_excluding_function_types(): Parsed<NTypePattern> {
    let span = lexer.current_token_span

    // Any
    if lexer.current_token_kind == TokenKind::MUL {
        lexer.next_token()
        ret found(NTypePattern @[
            span,
            kind: TypePatternKind::TYPE_ANY,
            name: "*",
            path: "",
            params: [],
            resolved: None(),
        ])
    }

    // #A
    if lexer.current_token_kind == TokenKind::HASH {
        lexer.next_token()
        let name: String = read_name()?

        ret found(NTypePattern @[
            span,
            kind: TypePatternKind::TYPE_PARAM,
            name,
            path: "",
            params: [],
            resolved: None(),
        ])
    }

    // (Int, Boolean) -> Float
    // Not allowed

    // <T>
    if lexer.current_token_kind == TokenKind::LTH {
        lexer.next_token()

        skip_nl()
        let type_pattern = read_type_pattern()?
        skip_nl()

        skip_token_kind(TokenKind::GTH)?

        ret found(type_pattern)
    }

    // core::Int, List<Int>
    let path: String = read_module_path()?
    let name: String = read_name()?
    let params: List<NTypePattern> = []

    if lexer.current_token_kind == TokenKind::LTH {
        params = read_type_pattern_param_args()?
    }

    let ty = NTypePattern @[
        span,
        kind: TypePatternKind::TYPE_SIMPLE,
        name,
        path,
        params,
        resolved: None(),
    ]

    // Int.() -> Nothing
    // Not allowed

    ret found(ty)
}

// <A, B, C>
fun Parser.read_type_pattern_param_args(): Parsed<List<NTypePattern>> {
    let list: List<NTypePattern> = []
    skip_token_kind(TokenKind::LTH)?

    skip_nl()
    read_until_delimited(TokenKind::GTH) @{
        list[] = read_type_pattern()?
        ret found(nothing)
    }?

    ret found(list)
}

// (Int, Boolean)->Float
fun Parser.read_function_type_pattern(arg1: Optional<NTypePattern>, span: Span): Parsed<NTypePattern> {
    // // (Int) -> Int
    // functionTypePattern
    //       : LPAREN RPAREN ARROW typePattern
    //       | LPAREN functionTypePatternParam (commaOrNl functionTypePatternParam)* RPAREN ARROW typePattern
    //       ;
    let params = []

    if arg1.is_some() {
        params[] = arg1!!
    }

    skip_token_kind(TokenKind::LPAREN)?
    skip_nl()
    read_until_delimited(TokenKind::RPAREN) @{
        lexer.next_token()
        params[] = read_function_type_pattern_param()?
        ret found(nothing)
    }?

    skip_token_kind(TokenKind::RPAREN)?
    skip_token_kind(TokenKind::ARROW)?

    params[] = read_type_pattern()?

    ret found(NTypePattern @[
        span,
        kind: TypePatternKind::TYPE_SIMPLE,
        name: "Function",
        path: "",
        params,
        resolved: None(),
    ])
}

fun Parser.read_function_type_pattern_param(): Parsed<NTypePattern> {
    // // a, a: Int
    // functionTypePatternParam
    //       : typePattern
    //       | anyName COLON typePattern
    //       ;

    // Skip name, is only for documentation
    if lexer.next_token_kind == TokenKind::COLON {
        let name: String = read_name()?
        skip_token_kind(TokenKind::COLON)?
    }

    ret read_type_pattern()
}
