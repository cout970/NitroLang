
// typeParamsDef
//      : LTH NL* typeParamDef (commaOrNl typeParamDef)* COMMA? NL* GTH ;
//
// typeParamDef
//       : typeParameter COLON typeUsage (COMMA typeUsage)*
//       | typeParameter
//       ;
//
// // #T, #A, #B, List<#A>
// typeParameter
//       : HASH anyName ;

struct NGeneric {
    id_wrapper: IdWrapper
    span: Span
    name: String
    constraints: List<NGenericConstraint>
}

struct NGenericParams {
    definitions: List<NGeneric>
    type_tokens: List<TypeToken>
}

struct NGenericConstraint {
    name: String
    tag_definition: Optional<NTag>
}

fun NGenericParams::new(): NGenericParams {
    ret NGenericParams @[
        definitions: [],
        type_tokens: [],
    ]
}

fun NGenericParams.get(name: String): Optional<NGeneric> {
    for def in definitions {
        if def.name == name {
            ret Some(def)
        }
    }
    ret None()
}

// <#T, #A>
fun Parser.read_type_params_def(): Parsed<Nothing> {
    if lexer.current_token_kind != TokenKind::LTH {
        ret found(nothing)
    }

    // Skip `<`
    lexer.next_token()

    read_until_delimited(TokenKind::GTH) @{
        current_generics.definitions[] = read_type_param_def()?
        ret found(nothing)
    }?

    ret found(nothing)
}

fun Parser.read_type_param_def(): Parsed<NGeneric> {
    // `#A: Type1, Type2` or just `#B`
    let span = lexer.current_token_span
    let name = read_type_parameter()?

    let def = NGeneric @[
        id_wrapper: id_provider.next(),
        span,
        name,
        constraints: []
    ]

    if lexer.current_token_kind != TokenKind::COLON {
        ret found(def)
    }

    lexer.next_token()

    def.constraints[] = NGenericConstraint @[name: read_name()?, tag_definition: None()]

    loop {
        // End of the list
        if lexer.current_token_kind != TokenKind::COMMA {
            break
        }

        // Break so read_type_params_def() can read the next item
        if lexer.next_token_kind == TokenKind::HASH {
            break
        }

        // Skip comma
        lexer.next_token()

        // Found new constraint
        if lexer.current_token_kind != TokenKind::HASH {
            def.constraints[] = NGenericConstraint @[name: read_name()?, tag_definition: None()]
        }
    }

    ret found(def)
}

fun Parser.read_type_parameter(): Parsed<String> {
    if lexer.current_token_kind != TokenKind::HASH {
        ret parse_error(ParseError::ExpectedTypeParameter, lexer.current_token)
    }

    // Skip `#`
    lexer.next_token()

    ret read_name()
}

fun NGeneric.get_hash(): Int = id_wrapper.id
fun NGeneric.get_ordering(other: NGeneric): Ordering = id_wrapper.id.get_ordering(other.id_wrapper.id)

fun NGeneric.to_string(): String {
    if constraints.is_empty() {
        ret "#$name"
    }
    let s = constraints.join_to_string(", ") @{ i -> i.name }

    ret "#$name: s"
}

fun NGenericParams.to_string(): String {
    if definitions.is_empty() {
        ret ""
    }

    let s = ""

    for def in definitions {
        if s.is_not_empty() {
            s += ", "
        }
        s += def.to_string()
    }

    ret "<$s>"
}